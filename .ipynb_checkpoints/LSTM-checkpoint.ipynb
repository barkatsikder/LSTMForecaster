{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand Forecasting using Long Short-Term Memory (LMST)\n",
    "\n",
    "##### based on https://github.com/IBM/forecast-demand-for-vending-machines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import math, time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import newaxis\n",
    "from pandas import read_csv\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'body' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9631ed261b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_data_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_data_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'body' is not defined"
     ]
    }
   ],
   "source": [
    "# read rename convert\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.head()\n",
    "series = df_data_1\n",
    "series = series.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-da3bf85dbe7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'series' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot series\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(series.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "series = series.values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "series = scaler.fit_transform(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 train test split\n",
    "train_size = int(len(series) * 0.80)\n",
    "test_size = len(series) - train_size\n",
    "train, test = series[0:train_size,:], series[train_size:len(series),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to create train test data sets\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# create train test datasets\n",
    "look_back = 20\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# review the shapes of these 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM requires 3D data so reshape\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "# review the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM model\n",
    "print('Build Model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(20,1), kernel_initializer=\"uniform\", return_sequences=True, stateful=False, units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, kernel_initializer=\"uniform\", activation='relu',return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#optimizer = Adam(lr=0.01)\n",
    "#model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "model.compile(loss=\"mse\", optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# params = 4 * (size_of_input + 1 * size_of_output) + 4 * size_of_output^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor the accuracy of validation loss ('val_loss') and end the training if there's no improvement in the accuracy after five iterations.\n",
    "# One of the methods to optimize computation time\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "start = time.time()\n",
    "history = model.fit(trainX, trainY, batch_size=72, epochs=25, verbose=1, shuffle=False, validation_split=0.10, callbacks=[early_stopping])\n",
    "print(\"> Compilation Time : \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model accuracy\n",
    "\n",
    "def model_score(model, trainX, trainY, testX, testY):\n",
    "    trainScore = model.evaluate(trainX, trainY, batch_size=72, verbose=0)\n",
    "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
    "\n",
    "    testScore = model.evaluate(testX, testY, batch_size=72, verbose=0)\n",
    "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))\n",
    "    return trainScore, testScore\n",
    "\n",
    "model_score(model, trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the learning of training & validation loss (error evaluation)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configuration info\n",
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot predicted vs actual values\n",
    "def plot_the_results(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white', figsize=(16,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.plot(padding + data, 'b^')\n",
    "    plt.show()\n",
    "    \n",
    "# function to predict future values\n",
    "def predict_the_sequences(model, data, window_size, prediction_len):\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs\n",
    "\n",
    "'''Predict future values & plot the results\n",
    "   In this case, we are predicting the current values.\n",
    "   If we need to predict t+1 then the prediction_len parameter has to be changed to 2\n",
    "   and if we need t+2 then prediction_len would be 3'''\n",
    "\n",
    "predictions = predict_the_sequences(model, testX, 20, 1)\n",
    "\n",
    "plot_the_results(predictions, testY, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for testing accuracy\n",
    "# apparently use GPU because expensive\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def build_regressor():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(input_shape=(20,1), kernel_initializer=\"uniform\", return_sequences=True, stateful=False, units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50, kernel_initializer=\"uniform\", activation='relu',return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss = \"mse\")\n",
    "    model.fit(trainX, trainY)\n",
    "    return regressor\n",
    "regressor = KerasRegressor(build_fn = build_regressor, batch_size = 72, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = regressor, X = trainX, y = trainY, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning\n",
    "# also apparently use GPU because expensive\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "regressor = KerasRegressor(build_fn = build_regressor)\n",
    "parameters = {'batch_size': [42, 62, 82],\n",
    "              'epochs': [50, 75, 100],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = regressor,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(trainX, trainY)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Denormalize the predicted values and review.\n",
    "   Convert the predicted output to a dataframe & print the results'''\n",
    "\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "results = pd.DataFrame(np.round(predictions[-10:]))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning related info (end of 11.5)\n",
    "\n",
    "\n",
    "# Transfer learning - where the money at $$$\n",
    "model.save('my_model.h5')\n",
    "print('Model saved to current directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "model = load_model('filepath/my_model.h5')\n",
    "print('Model loaded to the session')\n",
    "\n",
    "#read rename convert\n",
    "print(df_data_2.head())\n",
    "print(df_data_2.shape)\n",
    "\n",
    "new_series = df_data_2\n",
    "new_series = new_series.astype(float)\n",
    "new_series.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(new_series.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and reshape\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "new_data = scaler.fit_transform(new_series)\n",
    "print(len(new_data))\n",
    "\n",
    "look_back = 20\n",
    "new_testX, new_testY = create_dataset(new_data, look_back)\n",
    "\n",
    "new_testX = np.reshape(new_testX, (new_testX.shape[0], new_testX.shape[1], 1))\n",
    "new_testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize by stopping early\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy using three arguments \n",
    "\n",
    "def model_score_new(model, new_testX, new_testY):\n",
    "    NewModelScore = model.evaluate(new_testX, new_testY, batch_size=72, verbose=0)\n",
    "    print('NewModel Score: %.5f MSE (%.2f RMSE)' % (NewModelScore, math.sqrt(NewModelScore)))\n",
    "    return NewModelScore\n",
    "\n",
    "model_score_new(model, new_testX, new_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot comparison - future values vs results\n",
    "\n",
    "predictions = predict_the_sequences(model, new_testX, 20, 1)\n",
    "\n",
    "plot_the_results(predictions, new_testY, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model for reuse\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"filepath/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"filepath/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model architecture can be loaded and rebuilt with different configuration\n",
    "\n",
    "json_file = open('filepath/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "\n",
    "loaded_model.load_weights(\"filepath/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# compile, now that model has been loaded\n",
    "loaded_model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the new model\n",
    "\n",
    "start = time.time()\n",
    "loaded_model.fit(new_testX, new_testY, batch_size=72, epochs=15, verbose=1, shuffle=False, validation_split=0.05, callbacks=[early_stopping])\n",
    "print(\"> Compilation Time : \", time.time() - start)\n",
    "\n",
    "# Evaluate accuracy\n",
    "\n",
    "model_score_new(model, new_testX, new_testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict future values & plot the results\n",
    "\n",
    "predictions = predict_the_sequences(model, new_testX, 20, 1)\n",
    "plot_the_results(predictions, new_testY, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
